---

copyright:
  years: 2015, 2019
lastupdated: "2019-07-08"

subcollection: text-to-speech

---

{:shortdesc: .shortdesc}
{:external: target="_blank" .external}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:deprecated: .deprecated}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

# 服務背後的科學
{: #science}

{{site.data.keyword.texttospeechfull}} 服務提供的語音依賴兩種類型的技術：[神經語音技術](#science-neural)和[拼接合成](#science-concatenative)。這兩種技術都是將輸入文字合成為語音，但它們使用不同的方法來產生具有不同性質的音訊。神經 (`V3`) 語音是服務的原始拼接語音的增強版本。
{: shortdesc}

將文字合成為語音的主題本質上十分複雜。如需服務語音技術背後科學研究的相關資訊，請參閱[研究參考資料](/docs/services/text-to-speech?topic=text-to-speech-references)中列出的文件。

## 神經語音技術
{: #science-neural}

神經語音技術將輸入文字合成為接近人類的語音。服務首先會分析輸入文字，以確定需要的內容。與其拼接模型一樣，服務使用由決策樹狀結構組成的聲學模型來產生候選單位以供合成。

對於要合成之一系列電話中的每通電話，模型會考量前兩通與後兩通電話之上下文中的電話。然後，服務會產生一組聲學單位，並將評估其適用性。此步驟可減少搜尋的複雜性，方法是將其限制為僅限那些符合部分上下文準則的單位，並捨棄所有其他單位。

然後，服務使用三個深度神經網路 (DNN) 來預測語音的聲學（譜）特性，並將產生的音訊編碼：

-   韻律預測
-   聲學特性預測
-   神經聲碼器

在合成期間，DNN 會預測語音的音高和標音持續時間（韻律）、音譜結構和波形。例如，韻律預測模組會根據從輸入文字中擷取的語言特性來產生目標值。這些特性包含詞性、詞彙重音、字級突出處和位置特性（例如，句子中音節或字組的位置）等屬性。

DNN 根據自然人語音進行訓練，以預測音訊的聲學特性。此模組化方法的優勢是能夠進行快速輕鬆的訓練，以及獨立控制每個元件。訓練基礎網路之後，它們可以針對品牌行銷和個人化目的調整為新的說話風格或語音。

神經語音會產生清脆而清楚的語音，且音訊品質會聽起來很自然平順。如需服務神經語音技術的相關資訊，請參閱

-   部落格文章 [IBM Watson Text to Speech: Neural Voices Generally Available](https://medium.com/ibm-watson/ibm-watson-text-to-speech-neural-voices-added-to-service-e562106ff9c7){: external}
-   研究論文 [High quality, lightweight and adaptable Text to Speech using LPCNet](https://arxiv.org/abs/1905.00590){: external}

## 拼接合成
{: #science-concatenative}

拼接合成依賴大型合成語料庫中的聲學單位庫存，以產生任意輸入文字的輸出語音。它是以處理程序的下列管線為基礎。這些處理程序可協助對此單位庫存進行有效的即時搜尋，後面接著進行這些單位的後處理。


-   **聲學模型** - 此模型包含決策樹狀結構，負責產生候選單位進行搜尋。對於要合成之一系列電話中的每通電話，模型會考量前兩通與後兩通電話之上下文中的電話。然後，它會產生一組供搜尋評估適合程度的聲學單位。此步驟可有效地減少搜尋的複雜性，方法是將其限制為僅限那些符合部分上下文準則的單位，並捨棄所有其他單位。
-   **韻律目標模型** - 某些語音的韻律目標模型基於深度循環神經網路 (RNN)。對於其他語音，這些模型依賴決策樹狀結構來確定韻律。在這兩種情況下，模型都負責根據從輸入文字中擷取的一系列語言特性，產生語音韻律方面的目標值（例如，持續時間和語調）。此清單包括詞性、詞彙重音、字級突出處，以及位置特性（例如，句子中音節或字組的位置）這類屬性。韻律目標模型可協助指導搜尋符合這些模型預測的韻律條件的單位。
-   **搜尋** - 假設聲學模型和目標韻律傳回候選清單，此模組就會執行「維特比」搜尋。搜尋會擷取一系列的聲學單位，將成本函數降至最低，這會同時考量拼接和目標成本。因此，結合兩個單位所產生的有聲構件會縮至最小，而且模組會嘗試近似韻律目標模組所建議的目標韻律。此搜尋也會優先處理合成語料庫中的連續片段，以進一步減少這類構件。
-   **產生波形** - 當搜尋傳回最佳的單位系列時，系統會使用時域 Pitch Synchronous Overlap and Add (PSOLA) 來產生輸出波形。PSOLA 是用於語音處理的數位簽章處理技術。具體而言，它用於語音合成。它可以修改語音信號的音高和持續時間，並以無縫方式混合搜尋所傳回的單位。

    對於先前後端處理程序中的所有語言特性，服務會使用文字處理前端系統來剖析文字，然後將文字合成為音訊格式。前端系統會凈化任何格式化構件（例如 HTML 標籤）的文字。然後，它會使用和語言有關的語言規則所驅動的專有語言來準備文字並產生發音。此模組會將和語言有關的文字特性（例如日期、時間、數字及貨幣）正規化。例如，它會從字典執行縮寫展開，以及從序數和基數的規則執行數字展開。

    部分字組具有多個允許的發音，因此在執行時期，文字處理前端系統會先產生單一標準發音。此方法可能不會反映說話者在音訊語料庫進行錄製時所使用的發音。因此，服務會利用替代格式擴增一組候選發音，這些格式庫存於替代基礎格式字典中。它可讓搜尋根據音高、持續時間以及鄰近關係和限制來選擇降低成本的格式。此演算法可協助從資料集選取較長的連續片段，而在合成結果中產生最佳的語音流程。
