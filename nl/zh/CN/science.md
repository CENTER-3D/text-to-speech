---

copyright:
  years: 2015, 2019
lastupdated: "2019-07-08"

subcollection: text-to-speech

---

{:shortdesc: .shortdesc}
{:external: target="_blank" .external}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:deprecated: .deprecated}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

# 服务背后的科学
{: #science}

{{site.data.keyword.texttospeechfull}} 服务提供的声音依赖两种类型的技术：[神经声音技术](#science-neural)和[拼接合成](#science-concatenative)。这两种技术都是将输入文本合成为语音，但它们使用不同的方法来生成具有不同特征的音频。神经 (`V3`) 声音是服务的原始拼接声音的增强版本。
{: shortdesc}

将文本合成为语音的主题本质上十分复杂。有关服务语音技术背后的科学研究的更多相关信息，请参阅[研究参考资料](/docs/services/text-to-speech?topic=text-to-speech-references)中列出的文档。

## 神经声音技术
{: #science-neural}

神经声音技术将输入文本合成为接近人类的语音。服务首先会分析输入文本，以确定需要的内容。与其拼接模型一样，服务使用由决策树组成的声学模型来生成候选单元以供合成。

对于要合成的音素序列中的每个音素，模型会将音素放在前后两个音素的上下文中进行考虑。然后，服务会生成一组声学单元，并将评估其适用性。此步骤通过将搜索仅限于满足某些上下文条件的单元，而废弃其他所有单元，从而降低了搜索的复杂性。

然后，服务使用三个深度神经网络 (DNN) 来预测语音的声学（谱）特征，并将生成的音频编码：

-   韵律预测
-   声学特征预测
-   神经声码器

在合成期间，DNN 会预测语音的音高和音位持续时间（韵律）、谱结构和波形。例如，韵律预测模块会根据从输入文本中抽取的语言特征来生成目标值。这些特征包含词性、词重音、词级别突显和位置特征（例如，句子中音节或词的位置）等属性。

DNN 通过自然的人声进行训练，以预测音频的声学特征。此模块化方法的优势是支持快速轻松的训练，以及独立控制每个组件。训练基本网络之后，它们可以针对品牌形象和个性化目的调整为新的说话风格或声音。

神经声音生成的语音既清脆又清晰，具有非常自然且流畅的音频质量。有关服务的神经声音技术的更多信息，请参阅

-   博客帖子 [IBM Watson Text to Speech: Neural Voices Generally Available](https://medium.com/ibm-watson/ibm-watson-text-to-speech-neural-voices-added-to-service-e562106ff9c7){: external}
-   研究论文 [High quality, lightweight and adaptable Text to Speech using LPCNet](https://arxiv.org/abs/1905.00590){: external}

## 拼接合成
{: #science-concatenative}

拼接合成依赖于大型合成语料库中的声学单元清单来为任意输入文本生成输出语音。此服务基于以下过程管道。这些过程有助于通过此单元清单进行高效、实时搜索，然后对单元进行后处理。


-   **声学模型** - 此模型由决策树组成，决策树负责为搜索生成候选单元。对于要合成的音素序列中的每个音素，模型会将音素放在前后两个音素的上下文中进行考虑。然后，服务会生成一组声学单元，搜索将评估其适用性。此步骤通过将搜索限制为仅搜索满足某些上下文条件的单元，而废弃其他所有单元，从而有效地降低了搜索的复杂性。
-   **韵律目标模型** - 某些声音的韵律目标模型基于深度循环神经网络 (RNN)。对于其他声音，这些模型依赖决策树来确定韵律。在这两种情况下，模型都负责根据从输入文本中抽取的一系列语言特征，生成语音韵律方面的目标值（例如，持续时间和语调）。此列表包含词性、词重音、词级别突显和位置特征（例如，句子中音节或词的位置）等属性。韵律目标模型可帮助指导搜索满足这些模型预测的韵律条件的单元。
-   **搜索** - 根据声学模型和目标韵律返回的候选项列表，此模块会执行维特比搜索。搜索会抽取用于将开销函数降至最低的声学单元序列，这将同时考虑拼接和目标开销。因此，可以最大限度地减少连接两个单元的音频工件，并且此模块会尝试接近韵律目标模型所建议的目标韵律。此搜索还支持合成语料库中的连续块，以进一步减少此类工件。
-   **波形生成** - 搜索返回最佳单元序列时，系统会使用时域基音同步叠加法 (PSOLA) 来生成输出波形。PSOLA 是一种数字信号处理技术，用于语音处理。具体来说，此技术是用于语音合成。PSOLA 可以修改语音信号的音高和持续时间，并以无缝方式混合搜索返回的单元。

    对于先前后端过程中的所有语言特征，服务会使用文本处理前端来解析文本，然后将文本合成为音频格式。前端会对任何格式设置工件（如 HTML 标记）的文本进行清理。然后，前端会使用与语言相关的语言规则驱动的专有语言来准备文本并生成发音。此模块对文本的语言相关特征（例如，日期、时间、数字和货币）进行规范化。例如，它可通过字典执行缩写扩展，而通过序数和基数的规则来进行数字扩展。

    一些词具有多个允许的发音，因此文本处理前端在运行时会首先生成单个规范发音。此方法可能不会反映出在记录音频语料库时说话者使用的发音。因此，服务会使用在替代基本形式字典中列出的替代形式清单来扩充候选发音集。服务允许搜索选择不同形式，以降低音高、持续时间以及连续性顾虑和约束方面的开销。此算法有助于从数据集选择较长的连续块，从而在合成结果中生成最佳的语音流。
