---

copyright:
  years: 2015, 2019
lastupdated: "2019-03-07"

subcollection: text-to-speech

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}
{:tip: .tip}
{:important: .important}
{:note: .note}
{:deprecated: .deprecated}
{:pre: .pre}
{:codeblock: .codeblock}
{:screen: .screen}
{:javascript: .ph data-hd-programlang='javascript'}
{:java: .ph data-hd-programlang='java'}
{:python: .ph data-hd-programlang='python'}
{:swift: .ph data-hd-programlang='swift'}

# サービスの背景にある科学
{: #science}

{{site.data.keyword.texttospeechshort}} サービスは、任意の入力テキストに対し、大規模な合成コーパスに由来する音響ユニットのインベントリーを基にして出力音声を生成する連結的システムです。これは、以下のプロセスで構成されるパイプラインに基づいています。これらのプロセスにより、このユニットのインベントリーを効率的にリアルタイムで検索し、それに続いてユニットの後処理を行うことが簡単になります。
{: shortdesc}

-   **音響モデル** - このモデルは、検索に対して候補ユニットを生成するデシジョン・ツリーから構成されます。合成する音のシーケンスに含まれる 1 音ごとに、モデルは、その音の直前および直後の 2 つの音のコンテキストを考慮します。その後、検索の適合性を評価する音響ユニットのセットを生成します。このステップで、あるコンテキスト基準を満たすユニットのみに検索を制限し、他のすべてを破棄することによって、検索の複雑さが効果的に軽減されます。
-   **韻律ターゲット・モデル** - このモデルは、Deep Recurrent Neural Networks (RNN) で構成されます。 入力テキストから抽出された一連の言語特性を元に、モデルでは音声の韻律的な面 (長さやイントネーションなど) に対してターゲット値を生成します。 このリストには、品詞、語彙強勢、単語レベルのプロミネンス、位置特性 (例えば、センテンス内の音節または単語の位置) などの属性が含まれます。 韻律ターゲット・モデルは、このモデルによって予測された韻律基準を満たすユニットへと検索を導きます。
-   **検索** - 音響モデルおよびターゲット韻律から候補のリストが返されると、このモジュールは、Viterbi 検索を実行します。この検索では、連結コストとターゲット・コストの両方を考慮するコスト関数が最小になる音響ユニットのシーケンスが抽出されます。その結果、2 つのユニットを連結してできる音響成果物が最少化されます。また、このモジュールは、韻律ターゲット・モデルから提示されたターゲット韻律に近づけようとします。この検索では、合成コーパス内の連続チャンクが優先的に選択されるため、そのような成果物がさらに削減されます。
-   **波形の生成** - 検索から最適なユニットのシーケンスが返されたら、システムは、時間領域の Pitch Synchronous Overlap and Add (PSOLA) を使用して、出力波形を生成します。PSOLA は、音声処理に使用されるデジタル信号処理技法です。特に音声合成に使用されます。音声信号のピッチと持続時間を変更し、検索で返されたユニットをシームレスに一体化できます。

    前述のバックエンド処理における言語特性のすべてについて、サービスは、テキスト処理フロントエンドを使用してテキストを解析してから、音声形式に変換します。このフロントエンドは、HTML タグなどのフォーマット設定成果物のテキストをサニタイズします。次に、言語依存の言語学的ルールによって駆動される専有の言語を使用して、テキストを準備し、発音を生成します。 このモジュールは、日付、時間、数値、通貨など、テキストの言語依存の特性を正規化します。例えば、辞書に基づいて略語を展開したり、序数および基数のルールを使用して数値を展開したりします。

    複数の発音が許容される単語もあるため、テキスト処理フロントエンドではまず、実行時に、単一の標準的発音を生成します。 この手法では、音声コーパスの記録時に話者が使用した発音が反映されない可能性があります。そのため、サービスは、代替基本形式辞書に登録されている代替形式を使用して、発音候補のセットを拡張します。ピッチ、持続時間、連続性の問題や制約の観点からコストが削減される形式を検索で選択できるようにします。このアルゴリズムにより、データ・セットからより長い連続チャンクが選択されやすくなるため、合成結果の音声のフローが最適化されます。

テキストからの音声合成のトピックは本質的に複雑であり、サービスについて何らかの説明をしようとすると、この短い要約では収まりきらないほど説明を深く掘り下げる必要があります。 このサービスを支えている科学的研究について詳しくは、[研究資料](/docs/services/text-to-speech/references.html)にリストしている資料を参照してください。
